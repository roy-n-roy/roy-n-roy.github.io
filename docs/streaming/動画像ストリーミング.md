## Webブラウザへの動画像ストリーミング配信
2019/10 現在、Webブラウザへの動画ストリーミング配信には、2種類の方法がある。  

### HTTP Live Streaming(HLS)
Apple社によって開発された、動画を配信するためのプロトコル。  
MP4(H.264, AAC)ファイルを分割したものと、マスターファイル、インデックスファイルと呼ばれるファイル(拡張子: .m3u8)を用いる。  

#### 配信方法
分割したファイル群をWebサーバに配置し、HTML5のvideoタグを用いて配信ができる。  

#### 詳細解説
!!! note
	HLSについては下記の記事が詳しかった。  
	[動画配信技術 その1 - HTTP Live Streaming(HLS) - Akamai Japan Blog](https://blogs.akamai.com/jp/2013/02/-1---http-live-streaminghls.html)

動画の分割と配置が必要なため、リアルタイム配信ではある程度の遅延が発生する。  

ffmpeg等で、ファイルの分割とインデックスファイルを作成可能。  

!!! example
	input.mp4からoutput.m3u8というインデックスファイルと  
	output001.ts, output002.tsといった分割されたmpeg2-tsファイルに変換する。  

	$ `ffmpeg -i input.mp4 -c:v libx264 -c:a libfdk_aac -f hls -hls_time 5 -movflags faststart -hls_playlist_type vod -hls_segment_filename "output%3d.ts" output.m3u8`



### Web Real-Time Communication(WebRTC)
Google社によって開発された、ボイスチャットやビデオチャットなどを実現するプロトコル。  
ブラウザやモバイルアプリケーションなどの間でのPeer-to-Peer通信で配信する。  

#### 配信方法
Webブラウザ上からWebカメラやスクリーン共有の動画などを配信することができる。
また、ベースがPeer-to-Peer通信のため、接続先情報の交換やNAT超えなどの仕組みが用意されている。  
HLSと比較すると遅延の少ないリアルタイム配信が可能。

#### クライアントライブラリ
時雨堂社の[WebRTC向けシグナリングサーバ Ayame](https://github.com/OpenAyame/ayame)と、[Ayame Web SDK](https://github.com/OpenAyame/ayame-web-sdk)ライブラリの利用が簡単だった。

#### サーバからの配信
同じく、時雨同社の[WebRTC Native Client Momo](https://github.com/shiguredo/momo)を利用することで、Video4Linuxドライバの入力デバイスから配信ができる。

!!! note
	下記の記事を参考にした。  
	[WebRTC スタックコトハジメ](https://gist.github.com/voluntas/6fcece7f424607c957d5)  
	[詳解 WebRTC](https://gist.github.com/voluntas/a9dc017ea85aea5ffb7db73af5c6b4f9)  
	[WebRTCにて(S)RTCPが必要な理由 - iwashi.co](http://iwashi.co/2014/12/12/why-do-we-need-rtcp-in-webrtc)  
